{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:31:55.599919Z",
     "start_time": "2025-04-17T15:31:55.595015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    \n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"#\"cpu\"#\"cuda:1\"\n",
    "GRAYSCALE = True"
   ],
   "id": "62f3d3041364bce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:31:55.750041Z",
     "start_time": "2025-04-17T15:31:55.689416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ],
   "id": "f41711e1410dd4a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:31:55.889302Z",
     "start_time": "2025-04-17T15:31:55.762589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ],
   "id": "5c813d88b6765420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ResNet-18 Model",
   "id": "76870b861baafe0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:31:55.989545Z",
     "start_time": "2025-04-17T15:31:55.976644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # because MNIST is already 1x1 here:\n",
    "        # disable avg pooling\n",
    "        #x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet18(num_classes):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[2, 2, 2, 2],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model\n"
   ],
   "id": "d654d40b0520118b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:31:56.170126Z",
     "start_time": "2025-04-17T15:31:56.010592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = resnet18(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ],
   "id": "f1efb973f9ef076e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "1dc3699e72775c62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:32:22.047449Z",
     "start_time": "2025-04-17T15:31:56.188575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ],
   "id": "6f6d45780b5168b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/001 | Batch 0000/0469 | Cost: 2.6379\n",
      "Epoch: 001/001 | Batch 0050/0469 | Cost: 0.1937\n",
      "Epoch: 001/001 | Batch 0100/0469 | Cost: 0.0785\n",
      "Epoch: 001/001 | Batch 0150/0469 | Cost: 0.0550\n",
      "Epoch: 001/001 | Batch 0200/0469 | Cost: 0.0362\n",
      "Epoch: 001/001 | Batch 0250/0469 | Cost: 0.1746\n",
      "Epoch: 001/001 | Batch 0300/0469 | Cost: 0.0542\n",
      "Epoch: 001/001 | Batch 0350/0469 | Cost: 0.1465\n",
      "Epoch: 001/001 | Batch 0400/0469 | Cost: 0.0438\n",
      "Epoch: 001/001 | Batch 0450/0469 | Cost: 0.0250\n",
      "Epoch: 001/001 | Train: 96.718%\n",
      "Time elapsed: 0.43 min\n",
      "Total Training Time: 0.43 min\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:32:52.068136Z",
     "start_time": "2025-04-17T15:32:50.644761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ],
   "id": "fa477241bd1f7dae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 96.90%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:33:14.856448Z",
     "start_time": "2025-04-17T15:33:14.726953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "    \n",
    "nhwc_img = np.transpose(features[0], axes=(1, 2, 0))\n",
    "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
    "plt.imshow(nhw_img, cmap='Greys');"
   ],
   "id": "2d61398ab9420ab0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:34:20.539066Z",
     "start_time": "2025-04-17T15:34:20.494116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "logits, probas = model(features.to(device)[0, None])\n",
    "print(probas)\n",
    "print('Probability 7 %.2f%%' % (probas[0][7]*100))"
   ],
   "id": "d258ba69f29823e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.4189e-08, 1.6431e-07, 1.0111e-06, 3.1235e-07, 1.1119e-06, 5.7951e-07,\n",
      "         2.1941e-09, 9.9999e-01, 5.5175e-07, 1.1052e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Probability 7 100.00%\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3894d7a7e2a6d7df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
